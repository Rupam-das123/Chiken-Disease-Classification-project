{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\minor(chicken)\\\\Chiken-Disease-Classification-project\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\minor(chicken)\\\\Chiken-Disease-Classification-project'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    training_data: Path\n",
    "    params_epochs: int\n",
    "    params_batch_size: int\n",
    "    params_is_augmentation: bool\n",
    "    params_image_size: list\n",
    "\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PrepareCallbacksConfig:\n",
    "    root_dir: Path\n",
    "    tensorboard_root_log_dir: Path\n",
    "    checkpoint_model_filepath: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chickenDisease.constants import *\n",
    "from chickenDisease.utils.common import read_yaml, create_directories\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_prepare_callback_config(self) -> PrepareCallbacksConfig:\n",
    "        config = self.config.prepare_callbacks\n",
    "        model_ckpt_dir = os.path.dirname(config.checkpoint_model_filepath)\n",
    "        create_directories([\n",
    "            Path(model_ckpt_dir),\n",
    "            Path(config.tensorboard_root_log_dir)\n",
    "        ])\n",
    "\n",
    "        prepare_callback_config = PrepareCallbacksConfig(\n",
    "            root_dir=str(config.root_dir),\n",
    "            tensorboard_root_log_dir=str(config.tensorboard_root_log_dir),\n",
    "            checkpoint_model_filepath=str(config.checkpoint_model_filepath)\n",
    "        )\n",
    "\n",
    "        return prepare_callback_config\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training = self.config.training\n",
    "        prepare_base_model = self.config.prepare_base_model\n",
    "        params = self.params\n",
    "        training_data = os.path.join(self.config.data_ingestion.unzip_dir, \"Chicken-fecal-images\")\n",
    "        create_directories([\n",
    "            Path(training.root_dir)\n",
    "        ])\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trained_model_path=Path(training.trained_model_path),\n",
    "            updated_base_model_path=Path(prepare_base_model.updated_base_model_path),\n",
    "            training_data=Path(training_data),\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_is_augmentation=params.AUGMENTATION,\n",
    "            params_image_size=params.IMAGE_SIZE\n",
    "        )\n",
    "\n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareCallback:\n",
    "    def __init__(self, config: PrepareCallbacksConfig):\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def _create_tb_callbacks(self):\n",
    "        timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "        tb_running_log_dir = os.path.join(\n",
    "            self.config.tensorboard_root_log_dir,\n",
    "            f\"tb_logs_at_{timestamp}\",\n",
    "        )\n",
    "        return tf.keras.callbacks.TensorBoard(log_dir=tb_running_log_dir)\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def _create_ckpt_callbacks(self):\n",
    "        return tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=self.config.checkpoint_model_filepath,\n",
    "            save_best_only=True\n",
    "        )\n",
    "\n",
    "\n",
    "    def get_tb_ckpt_callbacks(self):\n",
    "        return [\n",
    "            self._create_tb_callbacks,\n",
    "            self._create_ckpt_callbacks\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Using cached scipy-1.10.1-cp38-cp38-win_amd64.whl.metadata (58 kB)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in d:\\anaconda\\envs\\chicken\\lib\\site-packages (from scipy) (1.24.3)\n",
      "Downloading scipy-1.10.1-cp38-cp38-win_amd64.whl (42.2 MB)\n",
      "   ---------------------------------------- 0.0/42.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/42.2 MB 4.2 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 1.8/42.2 MB 5.3 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 3.1/42.2 MB 5.8 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 4.5/42.2 MB 6.0 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 5.2/42.2 MB 6.1 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 6.8/42.2 MB 5.7 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 7.9/42.2 MB 5.6 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 9.2/42.2 MB 5.7 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 10.5/42.2 MB 5.7 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 11.8/42.2 MB 5.8 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 13.1/42.2 MB 5.8 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 14.4/42.2 MB 5.9 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 15.7/42.2 MB 5.9 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 16.8/42.2 MB 5.8 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 18.1/42.2 MB 5.8 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 19.4/42.2 MB 5.9 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 20.7/42.2 MB 5.8 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 21.0/42.2 MB 5.8 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 21.0/42.2 MB 5.8 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 21.8/42.2 MB 5.2 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 22.8/42.2 MB 5.2 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 24.1/42.2 MB 5.2 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 25.2/42.2 MB 5.3 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 26.7/42.2 MB 5.3 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 28.0/42.2 MB 5.4 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 29.4/42.2 MB 5.4 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 30.7/42.2 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 32.2/42.2 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 33.3/42.2 MB 5.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 34.6/42.2 MB 5.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 35.7/42.2 MB 5.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 35.7/42.2 MB 5.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 35.7/42.2 MB 5.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 35.7/42.2 MB 5.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 35.7/42.2 MB 5.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 36.7/42.2 MB 4.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 38.0/42.2 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 39.3/42.2 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 40.4/42.2 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  41.7/42.2 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 42.2/42.2 MB 5.0 MB/s eta 0:00:00\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.10.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pillow\n",
      "  Using cached pillow-10.4.0-cp38-cp38-win_amd64.whl.metadata (9.3 kB)\n",
      "Downloading pillow-10.4.0-cp38-cp38-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.6 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.8/2.6 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 5.9 MB/s eta 0:00:00\n",
      "Installing collected packages: pillow\n",
      "Successfully installed pillow-10.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def get_base_model(self):\n",
    "        self.model = tf.keras.models.load_model(\n",
    "            self.config.updated_base_model_path\n",
    "        )\n",
    "    \n",
    "    def train_valid_generator(self):\n",
    "\n",
    "        datagenerator_kwargs = dict(\n",
    "            rescale = 1./255,\n",
    "            validation_split=0.20\n",
    "        )\n",
    "\n",
    "        dataflow_kwargs = dict(\n",
    "            target_size=self.config.params_image_size[:-1],\n",
    "            batch_size=self.config.params_batch_size,\n",
    "            interpolation=\"bilinear\"\n",
    "        )\n",
    "\n",
    "        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            **datagenerator_kwargs\n",
    "        )\n",
    "\n",
    "        self.valid_generator = valid_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"validation\",\n",
    "            shuffle=False,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "        if self.config.params_is_augmentation:\n",
    "            train_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                rotation_range=40,\n",
    "                horizontal_flip=True,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                **datagenerator_kwargs\n",
    "            )\n",
    "        else:\n",
    "            train_datagenerator = valid_datagenerator\n",
    "\n",
    "        self.train_generator = train_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"training\",\n",
    "            shuffle=True,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        model.save(path)\n",
    "\n",
    "\n",
    "    def train(self, callback_list: list):\n",
    "        self.steps_per_epoch = self.train_generator.samples // self.train_generator.batch_size\n",
    "        self.validation_steps = self.valid_generator.samples // self.valid_generator.batch_size\n",
    "\n",
    "        self.model.fit(\n",
    "            self.train_generator,\n",
    "            epochs=self.config.params_epochs,\n",
    "            steps_per_epoch=self.steps_per_epoch,\n",
    "            validation_steps=self.validation_steps,\n",
    "            validation_data=self.valid_generator,\n",
    "            callbacks=callback_list\n",
    "        )\n",
    "\n",
    "        self.save_model(\n",
    "            path=self.config.trained_model_path,\n",
    "            model=self.model\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-15 02:22:10,320: INFO: common: YAML file 'config\\config.yaml' loaded successfully]\n",
      "[2025-11-15 02:22:10,322: INFO: common: YAML file 'params.yaml' loaded successfully]\n",
      "[2025-11-15 02:22:10,324: INFO: common: created directory at: artifacts]\n",
      "[2025-11-15 02:22:10,325: INFO: common: created directory at: artifacts\\prepare_callbacks\\checkpoint_dir]\n",
      "[2025-11-15 02:22:10,326: INFO: common: created directory at: artifacts\\prepare_callbacks\\tensorboard_log_dir]\n",
      "[2025-11-15 02:22:10,329: INFO: common: created directory at: artifacts\\training]\n",
      "Found 78 images belonging to 2 classes.\n",
      "Found 312 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "19/19 [==============================] - 28s 1s/step - loss: 15.0522 - accuracy: 0.5135 - val_loss: 0.5636 - val_accuracy: 0.9062\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\chicken\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 26s 1s/step - loss: 7.8752 - accuracy: 0.6020 - val_loss: 12.5901 - val_accuracy: 0.6094\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 26s 1s/step - loss: 3.3860 - accuracy: 0.7399 - val_loss: 0.8591 - val_accuracy: 0.9219\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 26s 1s/step - loss: 3.4102 - accuracy: 0.7500 - val_loss: 1.1457 - val_accuracy: 0.8594\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 26s 1s/step - loss: 1.2297 - accuracy: 0.8547 - val_loss: 1.4160 - val_accuracy: 0.7969\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 26s 1s/step - loss: 1.3363 - accuracy: 0.8649 - val_loss: 1.0009 - val_accuracy: 0.8906\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 26s 1s/step - loss: 0.6162 - accuracy: 0.9189 - val_loss: 1.4300 - val_accuracy: 0.7969\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 26s 1s/step - loss: 1.0080 - accuracy: 0.9054 - val_loss: 1.2177 - val_accuracy: 0.8281\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 26s 1s/step - loss: 0.5395 - accuracy: 0.9223 - val_loss: 0.8282 - val_accuracy: 0.9219\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 27s 1s/step - loss: 1.2222 - accuracy: 0.8289 - val_loss: 2.9587 - val_accuracy: 0.7188\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prepare_callbacks_config = config.get_prepare_callback_config()\n",
    "    prepare_callbacks = PrepareCallback(config=prepare_callbacks_config)\n",
    "    callback_list = prepare_callbacks.get_tb_ckpt_callbacks()\n",
    "\n",
    "    training_config = config.get_training_config()\n",
    "    training = Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.train_valid_generator()\n",
    "    training.train(\n",
    "        callback_list=callback_list\n",
    "    )\n",
    "    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chicken",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
